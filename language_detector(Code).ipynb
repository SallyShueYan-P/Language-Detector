{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48cf87b7",
   "metadata": {},
   "source": [
    "# Language Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6eca63",
   "metadata": {},
   "source": [
    "The complete test-use process constitutes language assessment, which is considerably more than just administering a language test. In fact, the main objective of language evaluation is to provide us with better information so that we may make better judgments and take better actions in the field of language education. This Python program will assist us in this field by inputting a few sentences in a single language and returning the language of the sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19c79c",
   "metadata": {},
   "source": [
    "Done by: Joshua, Richard, Sally "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728dc3e4",
   "metadata": {},
   "source": [
    "# Previous Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c81b976",
   "metadata": {},
   "source": [
    "This method demonstrates splitting phrases down into words, which are then stored by characters to detect sentences and to return the langauages along with the score of which is the model’s best prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c949f",
   "metadata": {},
   "source": [
    "##  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bb799af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caad4df",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffa5bdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   language                                               text  length_text\n",
      "16       pt  Reinício da sessãoDeclaro reaberta a sessão do...       730576\n",
      "17       ro  Componenţa Parlamentului: a se vedea procesul-...       336424\n",
      "18       sk  Schválenie zápisnice z predchádzajúceho rokova...       328185\n",
      "19       sl  Sprejetje zapisnika predhodne seje: glej zapis...       308136\n",
      "20       sv  Återupptagande av sessionenJag förklarar Europ...       674945\n"
     ]
    }
   ],
   "source": [
    "fpath = getcwd()\n",
    "data = pd.read_csv('/Users/sallypang/Library/CloudStorage/OneDrive-JamesCookUniversity/MA 3831/MA 3831 - Assignment01/formatted_data.csv', \";\")\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599b6976",
   "metadata": {},
   "source": [
    "## Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8032df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(bow):\n",
    "    filtered = []\n",
    "    punctuations = \"!\\\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\"\n",
    "    for i in range(len(bow)):\n",
    "        word = bow[i]\n",
    "        for punctuation in punctuations:\n",
    "            if punctuation in word:\n",
    "                word = word.replace(punctuation, \"\")\n",
    "                break\n",
    "        filtered.append(word)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0862833",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {}\n",
    "for ind in data.index:\n",
    "    bow = data['text'][ind].lower().split(\" \")\n",
    "    bow = filter_tokens(bow)\n",
    "    bow = \"\".join(bow)\n",
    "    languages[data['language'][ind]] = bow\n",
    "\n",
    "charSet = set()\n",
    "for lang in languages.keys():\n",
    "    charSet = charSet.union(set(languages[lang]))\n",
    "\n",
    "for lang in languages.keys():\n",
    "    charDict = dict.fromkeys(charSet, 0)\n",
    "    for char in languages[lang]:\n",
    "        charDict[char] += 1\n",
    "\n",
    "    charDict = {key: value for key, value in sorted(charDict.items())}\n",
    "    languages[lang] = charDict\n",
    "\n",
    "df = pd.DataFrame(languages)\n",
    "\n",
    "indexes = {}\n",
    "for col in df.columns:\n",
    "    z = df[col].sort_values(ascending=False)\n",
    "    indexes[col] = z.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a1843",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32ba0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: Парламента\n",
      "\n",
      "bg: 71\n",
      "cs: 55\n",
      "da: 32\n",
      "de: 28\n",
      "el: 41\n",
      "en: 30\n",
      "es: 31\n",
      "et: 58\n",
      "fi: 27\n",
      "fr: 32\n",
      "hu: 50\n",
      "it: 33\n",
      "lt: 51\n",
      "lv: 59\n",
      "nl: 28\n",
      "pl: 55\n",
      "pt: 33\n",
      "ro: 56\n",
      "sk: 55\n",
      "sl: 57\n",
      "sv: 31\n"
     ]
    }
   ],
   "source": [
    "inputted_text = input(\"Enter text: \")\n",
    "print()\n",
    "inputted_text = inputted_text.lower().split(\" \")\n",
    "inputted_text = filter_tokens(inputted_text)\n",
    "inputted_text = \"\".join(inputted_text)\n",
    "charDict = dict.fromkeys(charSet, 0)\n",
    "for char in inputted_text:\n",
    "    charDict[char] += 1\n",
    "charDict = {key: value for key, value in sorted(charDict.items())}\n",
    "inputted_text = pd.DataFrame(charDict, index=[0])\n",
    "inputted_text = inputted_text.transpose()\n",
    "inputted_text = inputted_text.sort_values(ascending=False, by=0)\n",
    "inputted_text = list(inputted_text.index)\n",
    "\n",
    "for key in indexes.keys():\n",
    "    score = 0\n",
    "    for i in range(len(indexes[key])):\n",
    "        if df[key][indexes[key][i]] == 0:\n",
    "            break\n",
    "        if inputted_text.index(indexes[key][i]) < inputted_text.index(indexes[key][i + 1]):\n",
    "            score += 1\n",
    "    print(f\"{key}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2945e16",
   "metadata": {},
   "source": [
    "Despite the fact that this is simply the first layer of the algorithm, the program returns results with a low degree of accuracy. Since most languages use the same alphabets for the words, even though those words may have different meanings and this is one of the main contributing factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa32d25",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77337a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import nltk\n",
    "import csv\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a694d",
   "metadata": {},
   "source": [
    "# Exploratory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f725440",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'/Users/sallypang/Library/CloudStorage/OneDrive-JamesCookUniversity/MA 3831/MA 3831 - Assignment01/formatted_data.csv', \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74fadf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   language     21 non-null     object\n",
      " 1   text         21 non-null     object\n",
      " 2   length_text  21 non-null     int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 632.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d601b9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>length_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg</td>\n",
       "      <td>Състав на Парламента: вж. протоколиОдобряване ...</td>\n",
       "      <td>327263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs</td>\n",
       "      <td>Schválení zápisu z předchozího zasedání: viz z...</td>\n",
       "      <td>317927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da</td>\n",
       "      <td>Genoptagelse af sessionenJeg erklærer Europa-P...</td>\n",
       "      <td>678400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>Wiederaufnahme der SitzungsperiodeIch erkläre ...</td>\n",
       "      <td>747690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>el</td>\n",
       "      <td>Επαvάληψη της συvσδoυΚηρύσσω την επανάληψη της...</td>\n",
       "      <td>523277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en</td>\n",
       "      <td>Resumption of the sessionI declare resumed the...</td>\n",
       "      <td>690268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>es</td>\n",
       "      <td>Reanudación del período de sesionesDeclaro rea...</td>\n",
       "      <td>733658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>et</td>\n",
       "      <td>Eelmise istungi protokolli kinnitamine vaata p...</td>\n",
       "      <td>324119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fi</td>\n",
       "      <td>Istuntokauden uudelleenavaaminen Julistan perj...</td>\n",
       "      <td>694523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fr</td>\n",
       "      <td>Reprise de la sessionJe déclare reprise la ses...</td>\n",
       "      <td>756201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hu</td>\n",
       "      <td>Az előző ülés jegyzőkönyvének elfogadása: lásd...</td>\n",
       "      <td>330524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it</td>\n",
       "      <td>Ripresa della sessioneDichiaro ripresa la sess...</td>\n",
       "      <td>729712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lt</td>\n",
       "      <td>Ankstesnio posėdžio protokolų tvirtinimas žr. ...</td>\n",
       "      <td>318875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lv</td>\n",
       "      <td>Iepriekšējās sēdes protokola apstiprināšana sk...</td>\n",
       "      <td>323079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nl</td>\n",
       "      <td>Hervatting van de zittingIk verklaar de zittin...</td>\n",
       "      <td>718181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pl</td>\n",
       "      <td>Zatwierdzenie protokołu z poprzedniego posiedz...</td>\n",
       "      <td>317026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pt</td>\n",
       "      <td>Reinício da sessãoDeclaro reaberta a sessão do...</td>\n",
       "      <td>730576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ro</td>\n",
       "      <td>Componenţa Parlamentului: a se vedea procesul-...</td>\n",
       "      <td>336424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sk</td>\n",
       "      <td>Schválenie zápisnice z predchádzajúceho rokova...</td>\n",
       "      <td>328185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sl</td>\n",
       "      <td>Sprejetje zapisnika predhodne seje: glej zapis...</td>\n",
       "      <td>308136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sv</td>\n",
       "      <td>Återupptagande av sessionenJag förklarar Europ...</td>\n",
       "      <td>674945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language                                               text  length_text\n",
       "0        bg  Състав на Парламента: вж. протоколиОдобряване ...       327263\n",
       "1        cs  Schválení zápisu z předchozího zasedání: viz z...       317927\n",
       "2        da  Genoptagelse af sessionenJeg erklærer Europa-P...       678400\n",
       "3        de  Wiederaufnahme der SitzungsperiodeIch erkläre ...       747690\n",
       "4        el  Επαvάληψη της συvσδoυΚηρύσσω την επανάληψη της...       523277\n",
       "5        en  Resumption of the sessionI declare resumed the...       690268\n",
       "6        es  Reanudación del período de sesionesDeclaro rea...       733658\n",
       "7        et  Eelmise istungi protokolli kinnitamine vaata p...       324119\n",
       "8        fi  Istuntokauden uudelleenavaaminen Julistan perj...       694523\n",
       "9        fr  Reprise de la sessionJe déclare reprise la ses...       756201\n",
       "10       hu  Az előző ülés jegyzőkönyvének elfogadása: lásd...       330524\n",
       "11       it  Ripresa della sessioneDichiaro ripresa la sess...       729712\n",
       "12       lt  Ankstesnio posėdžio protokolų tvirtinimas žr. ...       318875\n",
       "13       lv  Iepriekšējās sēdes protokola apstiprināšana sk...       323079\n",
       "14       nl  Hervatting van de zittingIk verklaar de zittin...       718181\n",
       "15       pl  Zatwierdzenie protokołu z poprzedniego posiedz...       317026\n",
       "16       pt  Reinício da sessãoDeclaro reaberta a sessão do...       730576\n",
       "17       ro  Componenţa Parlamentului: a se vedea procesul-...       336424\n",
       "18       sk  Schválenie zápisnice z predchádzajúceho rokova...       328185\n",
       "19       sl  Sprejetje zapisnika predhodne seje: glej zapis...       308136\n",
       "20       sv  Återupptagande av sessionenJag förklarar Europ...       674945"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffd5a85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a5e41e",
   "metadata": {},
   "source": [
    "This \"formatted_data.csv\" dataset, which includes sentences in 21 different languages and along with \";\" as the separator. The language code, text, and the amount of characters in the designated language are listed in the first, second, and third columns, respectively. \n",
    "The texts in this database were taken from the European Union Proceedings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c9f43c",
   "metadata": {},
   "source": [
    "# Code for Languages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c0e08",
   "metadata": {},
   "source": [
    "$ bg - Bulgarian \\\\ cs - Czech \\\\  da - Danish \\\\  de - German \\\\  el - Greek \\\\ en - English \\\\ es - Spanish \\\\ et - Estonian \\\\ fi - Finnish \\\\ fr - French \\\\ hu - Hungarian \\\\  it - Italian \\\\ lt - Lithuanian \\\\ lv - Latvian \\\\ nl - Dutch \\\\ pl - Polish \\\\ pt - Portuguese \\\\ ro - Romanian \\\\ sk - Slovak \\\\ sl - Slovenian \\\\  sv - Swedish $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3209672",
   "metadata": {},
   "source": [
    "# Pre-process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a53fe",
   "metadata": {},
   "source": [
    "All text sentences from each language were split using the nltk function, and the data was then restored into a new csv file. Mark the language of each sentence in the Language column. Although there are many different types of methods, this is by far the most accurate and delivers the best results. We can easily proceed with tokenizing the variables by spitting out the text in each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb5072f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = []\n",
    "for ind in data.index:\n",
    "    lang = data[\"text\"][ind]\n",
    "    lang_list = nltk.tokenize.sent_tokenize(lang)\n",
    "    for sentence in lang_list:\n",
    "        new_sent = [sentence, data[\"language\"][ind]]\n",
    "        language.append(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384aac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "myFile = open('demo_file.csv', 'w')\n",
    "writer = csv.writer(myFile)\n",
    "writer.writerow(['Text', 'Language'])\n",
    "for data_list in language:\n",
    "    writer.writerow(data_list)\n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87f1e4",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa39c1",
   "metadata": {},
   "source": [
    "Retrieve dependent and independent variables by reading the new entity file (demo file.csv). In order to pre-process text data before creating the vector representation, CountVectorizer helps with tokenization as it has flexible feature representation module for text due to this functionality. Additionally since this is a multiclass classification problem, we utilised the Multinomial Naive Bayes technique to train the language detection model as it consistently delivers excellent results in multiclass classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea12522a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56886 entries, 0 to 56885\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      56886 non-null  object\n",
      " 1   Language  56886 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 889.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'/Users/sallypang/Library/CloudStorage/OneDrive-JamesCookUniversity/MA 3831/MA 3831 - Assignment01/demo_file.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4503a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df[\"Text\"])\n",
    "y = np.array(df[\"Language\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x) # performs fit and transform on the input data at a single time and converts the data points.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fdb6d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9932325540516787"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9798b022",
   "metadata": {},
   "source": [
    "# Test for Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09071f92",
   "metadata": {},
   "source": [
    "This section is to test 21 languages based on user's input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75990285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Languages\n",
      " *Enter to quit.\n",
      "------------------\n",
      "Enter a Text: Израилтяните нека поставят шатрите си, всеки при знамето си, със знаковете на бащиния си дом; срещу шатъра за срещане да поставят шатрите с и изоколо.\n",
      "['bg']\n",
      "Enter a Text: De aquí en adelante no daréis hornija al pueblo para hacer ladrillo, como ayer y antes de ayer; vayan ellos y recojan hornija por sí mismos .\n",
      "['es']\n",
      "Enter a Text: Keď prichádzal do Kafarnauma, pristúpil k nemu rímsky stotník a poprosil ho:\n",
      "['sk']\n",
      "Enter a Text: Azután vidd be az asztalt, és hozd azt rendbe a reávalókkal. Vidd be a gyertyatartót is, és gyújtsd meg annak mécseit.\n",
      "['hu']\n",
      "Enter a Text: ”Skulle de då få behandla vår syster som en prostituerad?” svarade de.\n",
      "['sv']\n",
      "Enter a Text: Elon Musk has said that he will step down as CEO of Twitter once a suitable replacement can be found. On Sunday he ran a poll asking if he should leave the role, and Twitter users overwhelmingly told him to go. He didn't immediately respond to the results, but by Tuesday he seemed to have ac cepted the will of the people, after originally suggesting that he might instead change it so that only paying users could vote in Twitter polls.\n",
      "['en']\n",
      "Enter a Text: \n",
      "------------------\n",
      "Test ended.\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Languages\\n *Enter to quit.\\n------------------\")\n",
    "user = input(\"Enter a Text: \")\n",
    "while user != \"\":\n",
    "    data = cv.transform([user]).toarray()\n",
    "    output = model.predict(data)\n",
    "    print(output)\n",
    "    user = input(\"Enter a Text: \")\n",
    "print(\"------------------\\nTest ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85748f7",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8816fd2d",
   "metadata": {},
   "source": [
    "Our language identification system's findings are presented, and we have looked at some of the problems with automatically determining a text's language. While some more modern algorithms perform with a similar level of accuracy, our solution utilizes a straightforward, widely accepted methodology. However, although the total number of languages in this project is only 21, some of languages share the same word spellings but have different meanings. For instance, even though we meant \"van\" in the language of \"en\", it will be recognized as the language \"nl\". As a result, our project's drawback is that the model performs less efficient when we are only testing a single word from a specific language. \n",
    "\n",
    "Our method stores each sentence instead of paragraph into separated cells as seen on the original file to conserve memory space and lower calculation costs while increasing efficiency since words may be easily identified in sentences to distinguish different languages. In addition, eliminating the stop words from the text of each phrase provided with the permission to use the corpus is part of our strategy to advance our project by improving the program better. It will help draw more attention to the important points. Furthermore, the project could be improved by increasing the quantity of unique words in each language."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
